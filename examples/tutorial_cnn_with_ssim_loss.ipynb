{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d304a3-801b-4f51-82d3-c65280ffca44",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5964c1-7a6e-45cd-a7ed-d9ec0403c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure as SSIM\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import our custom modules\n",
    "from model_utils import (\n",
    "    update_dropout_rates,\n",
    "    extract_dropout_rates,\n",
    "    extract_feature_maps,\n",
    "    replace_dropout_layers,\n",
    "    add_dropout_layers,\n",
    "    calc_CoV,\n",
    "    CatchFeatureMap\n",
    ")\n",
    "\n",
    "from evaluation_metrics import (\n",
    "    UncertaintyMetrics,\n",
    "    PredictivePowerMetrics\n",
    ")\n",
    "\n",
    "from baseline_dropouts import ConstantDropout, ScheduledDropout\n",
    "from adaptive_dropout import AdaptiveInformationDropout, OptimizerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d0549-6158-458f-9ace-26be4e3fd2da",
   "metadata": {},
   "source": [
    "# Define Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5bc543-f3c2-474d-9d0e-c31cddef44e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 1, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def train(model, x_train, y_train, epochs=1000, verbose=0):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if verbose and (epoch+1) % 200 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "    print('-------------------------------------')\n",
    "    print('Training Complete')\n",
    "    print('-------------------------------------')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808e74a5-8b9a-469e-866b-4976bef451f4",
   "metadata": {},
   "source": [
    "# Define Data Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b087c32d-2dc0-46f4-b534-b728ebf446c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(N=100, size=28):\n",
    "    \"\"\"Generate synthetic image data with simple patterns\"\"\"\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Create random patterns\n",
    "        img = np.zeros((size, size))\n",
    "        # Add random circles\n",
    "        for _ in range(3):\n",
    "            center = np.random.randint(5, size-5, 2)\n",
    "            radius = np.random.randint(2, 5)\n",
    "            y, x = np.ogrid[-center[0]:size-center[0], -center[1]:size-center[1]]\n",
    "            mask = x*x + y*y <= radius*radius\n",
    "            img[mask] = 1\n",
    "            \n",
    "        if i < N//2:\n",
    "            x_train.append(img)\n",
    "        else:\n",
    "            x_test.append(img)\n",
    "            \n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    return x_train, x_test\n",
    "\n",
    "def add_gaussian_noise(images, noise_level=0.1):\n",
    "    \"\"\"Add Gaussian noise to images\"\"\"\n",
    "    noise = np.random.normal(0, noise_level, images.shape)\n",
    "    noisy_images = np.clip(images + noise, 0, 1)\n",
    "    return noisy_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3107a8c-1b66-49d7-a3b3-25bcff13201f",
   "metadata": {},
   "source": [
    "# Define SSIM-based Information Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361e9bd0-258f-4830-8d3c-430e3861966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_information_loss(pre_dropout, post_dropout, properties={}):\n",
    "    \"\"\"\n",
    "    Calculate information loss using SSIM.\n",
    "    SSIM ranges from -1 to 1, where 1 means identical images.\n",
    "    We convert it to a loss ranging from 0 to 1.\n",
    "    \"\"\"\n",
    "    ssim_module = SSIM(data_range=1.0)\n",
    "    \n",
    "    # Ensure inputs are properly scaled to [0, 1]\n",
    "    pre_scaled = (pre_dropout - pre_dropout.min()) / (pre_dropout.max() - pre_dropout.min() + 1e-8)\n",
    "    post_scaled = (post_dropout - post_dropout.min()) / (post_dropout.max() - post_dropout.min() + 1e-8)\n",
    "    \n",
    "    # Calculate SSIM\n",
    "    ssim_score = ssim_module(pre_scaled, post_scaled)\n",
    "    \n",
    "    # Convert SSIM to loss (1 - SSIM) to get range [0, 1] (assuming non-negative SSIM values due to dropout)\n",
    "    information_loss = (1 - ssim_score)\n",
    "    \n",
    "    return information_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e6cc7b-9c8c-4703-ae8c-d7d145d6b4e6",
   "metadata": {},
   "source": [
    "# Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a27c0760-72fc-4da7-9332-009b9b51e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 123\n",
    "\n",
    "# Data Generation\n",
    "noise_level = 0.50\n",
    "N_samples = 100\n",
    "image_size = 28\n",
    "epochs = 1000\n",
    "\n",
    "# Dropout Configurations\n",
    "constant_dropout_rate = 0.10\n",
    "dropout_layers_placement = ['layers.0', 'layers.2'] \n",
    "\n",
    "# Rate-In Configuration\n",
    "information_loss_threshold = constant_dropout_rate\n",
    "optimizer_params = OptimizerConfig(\n",
    "    max_iterations=100,\n",
    "    learning_rate=0.10,\n",
    "    decay_rate=0.9,\n",
    "    stopping_error=0.01\n",
    ")\n",
    "verbose_rate_in = 0\n",
    "\n",
    "# Monte-Carlo Simulations\n",
    "MC_iters = 100\n",
    "\n",
    "# Evaluation metric\n",
    "mse_func = PredictivePowerMetrics.mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c87f6d-9374-4ef6-8374-2aaf42c45209",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b249045-559f-4a68-bcaf-b58bfeabec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Epoch [200/1000], Loss: 0.0100\n",
      "Epoch [400/1000], Loss: 0.0079\n",
      "Epoch [600/1000], Loss: 0.0074\n",
      "Epoch [800/1000], Loss: 0.0065\n",
      "Epoch [1000/1000], Loss: 0.0062\n",
      "-------------------------------------\n",
      "Training Complete\n",
      "-------------------------------------\n",
      "Base model MSE: 0.009321050718426704\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Generate data\n",
    "x_train, x_test = generate_synthetic_data(N_samples, image_size)\n",
    "x_train_noisy = add_gaussian_noise(x_train, noise_level)\n",
    "x_test = x_test[:1]\n",
    "\n",
    "# Convert to tensors and add channel dimension\n",
    "x_train_tensor = torch.from_numpy(x_train_noisy).float().unsqueeze(1)\n",
    "x_test_tensor = torch.from_numpy(x_test).float().unsqueeze(1)\n",
    "y_train_tensor = torch.from_numpy(x_train).float().unsqueeze(1)\n",
    "y_test_tensor = torch.from_numpy(x_test).float().unsqueeze(1)\n",
    "\n",
    "# Train base model\n",
    "model_full = SimpleCNN()\n",
    "print(model_full)\n",
    "model = train(model=model_full, x_train=x_train_tensor, y_train=y_train_tensor, \n",
    "             epochs=epochs, verbose=1)\n",
    "\n",
    "y_pred = model(x_test_tensor)\n",
    "print(f\"Base model MSE: {mse_func(y_pred, y_test_tensor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd4d178-53ef-42d8-b9cc-8d30f95cc3a8",
   "metadata": {},
   "source": [
    "# Inference Time MC-Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe3c68a-3e26-4446-a6f2-d0ba19ae78d8",
   "metadata": {},
   "source": [
    "##### Add constant dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca1ba32-dfa9-47d7-aa0c-0bdf7544df4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant dropout MSE: 0.04690108820796013\n"
     ]
    }
   ],
   "source": [
    "model_constant = add_dropout_layers(\n",
    "    model=copy.deepcopy(model_full),\n",
    "    dropoutLayer=torch.nn.Dropout(p=constant_dropout_rate),\n",
    "    placement_layers=dropout_layers_placement\n",
    ")\n",
    "\n",
    "y_pred = model_constant(x_test_tensor)\n",
    "print(f\"Constant dropout MSE: {mse_func(y_pred, y_test_tensor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e8015-ab23-4406-ac96-d8a7d9d2988e",
   "metadata": {},
   "source": [
    "##### Add adaptive Rate-In dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7761cb08-aba1-46df-875e-61c22e0ff82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured feature maps: ['layers.0.1', 'layers.2.1']\n",
      "layers.0.1: Current Dropout Rate: 10.0% | Loss: 0.112\n",
      "layers.0.1: Current Dropout Rate: 9.9% | Loss: 0.110\n",
      "layers.0.1: Final Dropout Rate: 9.8% | Loss: 0.110\n",
      "\n",
      "layers.2.1: Current Dropout Rate: 10.0% | Loss: 0.359\n",
      "layers.2.1: Current Dropout Rate: 8.2% | Loss: 0.308\n",
      "layers.2.1: Current Dropout Rate: 6.4% | Loss: 0.259\n",
      "layers.2.1: Current Dropout Rate: 5.1% | Loss: 0.216\n",
      "layers.2.1: Current Dropout Rate: 4.0% | Loss: 0.188\n",
      "layers.2.1: Current Dropout Rate: 3.2% | Loss: 0.154\n",
      "layers.2.1: Current Dropout Rate: 2.7% | Loss: 0.133\n",
      "layers.2.1: Current Dropout Rate: 2.4% | Loss: 0.121\n",
      "layers.2.1: Current Dropout Rate: 2.2% | Loss: 0.114\n",
      "layers.2.1: Current Dropout Rate: 2.0% | Loss: 0.105\n",
      "layers.2.1: Final Dropout Rate: 2.0% | Loss: 0.105\n",
      "\n",
      "Rate-In Model MSE: 0.025458302348852158\n",
      "\n",
      "Rate-In Dropout Rates: {'layers.0.1': 0.09798453568574325, 'layers.2.1': 0.019798150963449442}\n",
      "Updated dropout rate of layer 'layers.0.1' to 0.09798453568574325\n",
      "Updated dropout rate of layer 'layers.2.1' to 0.019798150963449442\n"
     ]
    }
   ],
   "source": [
    "# Capture feature maps\n",
    "model_clone = replace_dropout_layers(model_constant, layer_type='catcher')\n",
    "_ = model_clone(x_test_tensor)\n",
    "\n",
    "full_model_feature_maps = extract_feature_maps(model_clone)\n",
    "full_model_feature_maps = {v[0]:v[1] for v in full_model_feature_maps}\n",
    "\n",
    "if not full_model_feature_maps:\n",
    "    raise ValueError(\"No feature maps were captured! Check the model structure.\")\n",
    "\n",
    "print(\"Captured feature maps:\", list(full_model_feature_maps.keys()))\n",
    "\n",
    "# Setup layer properties for Rate-In\n",
    "layer_properties = {}\n",
    "for l_name, l_map in full_model_feature_maps.items():\n",
    "    layer_properties[l_name] = {\n",
    "        'calc_information_loss': calc_information_loss,\n",
    "        'initial_p': constant_dropout_rate,\n",
    "        'information_loss_threshold': information_loss_threshold,\n",
    "        'optimizer_config': optimizer_params,\n",
    "        'name': l_name,\n",
    "        'verbose': 2,\n",
    "        'properties': {}  # No additional properties needed for SSIM\n",
    "    }\n",
    "\n",
    "# Replace with adaptive layers\n",
    "model_adaptive = replace_dropout_layers(\n",
    "    model_constant,\n",
    "    layer_type='adaptive',\n",
    "    layer_properties=layer_properties\n",
    ")\n",
    "\n",
    "# Get Rate-In dropout rates and predictions\n",
    "model_adaptive.train()\n",
    "y_pred = model_adaptive(x_test_tensor)\n",
    "\n",
    "# Extract and display rates\n",
    "rates = {name: rate.item() for name, rate in extract_dropout_rates(model_adaptive)}\n",
    "\n",
    "print('Rate-In Model MSE:', mse_func(y_pred, y_test_tensor))\n",
    "print('\\nRate-In Dropout Rates:', rates)\n",
    "\n",
    "model_rate_in = update_dropout_rates(model = copy.deepcopy(model_constant), rates = rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5eef51-d5a0-42a7-9743-64260fe630de",
   "metadata": {},
   "source": [
    "### Add alternative baseline dropout approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6104d6d-2c76-4b85-832b-9962f67f4aa4",
   "metadata": {},
   "source": [
    "##### Add Activation-based dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c57b26c4-74e5-40aa-80b2-d1b15ac27d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dropout rate of layer 'layers.0.1' to 0.10000000149011612\n",
      "Updated dropout rate of layer 'layers.2.1' to 0.04093663766980171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Dropout(p=0.10000000149011612, inplace=False)\n",
       "    )\n",
       "    (1): ReLU()\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Dropout(p=0.04093663766980171, inplace=False)\n",
       "    )\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CoVs = [calc_CoV(l_map) for l_map in full_model_feature_maps.values()]\n",
    "rates_activation = dict(zip(full_model_feature_maps.keys(), constant_dropout_rate * (np.array(CoVs)/np.max(CoVs))))\n",
    "model_activation = update_dropout_rates(model = copy.deepcopy(model_constant), rates = rates_activation)\n",
    "\n",
    "model_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d5fc97-6cbb-46ad-bdaa-c723f442969d",
   "metadata": {},
   "source": [
    "##### Add Scheduled dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1309d2ce-2091-42f2-9eab-7cbea0509944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ScheduledDropout(p=0.10000000149011612, reps=100, iter=0, name=\"layers.0.dropout\")\n",
       "    )\n",
       "    (1): ReLU()\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ScheduledDropout(p=0.10000000149011612, reps=100, iter=0, name=\"layers.2.dropout\")\n",
       "    )\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scheduled = add_dropout_layers(\n",
    "    model_full,\n",
    "    ScheduledDropout(p=constant_dropout_rate, reps = MC_iters),\n",
    "    dropout_layers_placement\n",
    ")\n",
    "\n",
    "model_scheduled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c929709-9367-450d-b25c-7f658e1aab96",
   "metadata": {},
   "source": [
    "### Monte-Carlo Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4ad58e7-becf-40cc-b09a-a93b3656c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_inference(model, x, T=100):\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(T):\n",
    "            preds = model(x)\n",
    "            predictions.append(preds.numpy())\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    pred_mean = predictions.mean(axis=0)\n",
    "    pred_std = predictions.std(axis=0)\n",
    "\n",
    "    return torch.as_tensor(pred_mean), torch.as_tensor(pred_std)\n",
    "\n",
    "# Run MC dropout for all models\n",
    "PREDs = {}\n",
    "STDs = {}\n",
    "PREDs['Constant'], STDs['Constant'] = mc_dropout_inference(model_constant, x=x_test_tensor, T=MC_iters)\n",
    "PREDs['Rate-In'], STDs['Rate-In'] = mc_dropout_inference(model_rate_in, x=x_test_tensor, T=MC_iters)\n",
    "PREDs['Activation'], STDs['Activation'] = mc_dropout_inference(model_activation, x=x_test_tensor, T=MC_iters)\n",
    "PREDs['Scheduled'], STDs['Scheduled'] = mc_dropout_inference(model_scheduled, x=x_test_tensor, T=MC_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a80401-8c5b-40c1-8d29-bd10dfbf18ab",
   "metadata": {},
   "source": [
    "### Evaluate Prediction and Uncertainty Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db1afe9a-b68f-4f7d-8787-c1e04218b1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUC (Higher Better): 0.22. MSE (Lower Better): 0.01 | Constant\n",
      "BUC (Higher Better): 0.3. MSE (Lower Better): 0.01 | Rate-In\n",
      "BUC (Higher Better): 0.25. MSE (Lower Better): 0.01 | Activation\n",
      "BUC (Higher Better): 0.24. MSE (Lower Better): 0.01 | Scheduled\n"
     ]
    }
   ],
   "source": [
    "for approach in PREDs.keys():\n",
    "    mse_score = PredictivePowerMetrics.mse(PREDs[approach].squeeze(0,1).detach().cpu().numpy(), y_test_tensor.squeeze(0,1).detach().cpu().numpy())\n",
    "    buc_score = UncertaintyMetrics.boundary_uncertainty_consistency(STDs[approach].squeeze(0,1).detach().cpu().numpy(), y_test_tensor.squeeze(0,1).detach().cpu().numpy())\n",
    "    print('BUC (Higher Better): {}. MSE (Lower Better): {} | {}'.format(np.round(buc_score,2), np.round(mse_score,2), approach))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
