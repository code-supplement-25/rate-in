{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from adaptive_dropout import AdaptiveInformationDropout, OptimizerConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Simple MSE-based Information Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_information_loss(pre_dropout: torch.Tensor, post_dropout: torch.Tensor, properties: dict = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate a simple information loss between pre- and post-dropout vectors\n",
    "    using normalized mean squared error.\n",
    "    \n",
    "    This naive approach:\n",
    "    1. Calculates the mean squared error between vectors\n",
    "    2. Normalizes it by the magnitude of the pre-dropout vector\n",
    "    3. Returns a value between 0 and 1 where:\n",
    "       - 0 means no information loss (vectors are identical)\n",
    "       - 1 means maximum information loss (vectors are completely different)\n",
    "    \n",
    "    Args:\n",
    "        pre_dropout: Original tensor before dropout\n",
    "        post_dropout: Tensor after dropout application\n",
    "        properties: Optional additional properties (not used in this simple version)\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Scalar value representing information loss\n",
    "    \"\"\"\n",
    "    # Ensure inputs are float tensors\n",
    "    pre = pre_dropout.float()\n",
    "    post = post_dropout.float()\n",
    "    \n",
    "    # Calculate mean squared error\n",
    "    mse = torch.mean((pre - post) ** 2)\n",
    "    \n",
    "    # Normalize by the magnitude of the pre-dropout vector\n",
    "    # Add small epsilon to prevent division by zero\n",
    "    magnitude = torch.mean(pre ** 2) + 1e-8\n",
    "    \n",
    "    # Calculate normalized loss\n",
    "    loss = mse / magnitude\n",
    "    \n",
    "    # Clip to ensure value is between 0 and 1\n",
    "    loss = torch.clamp(loss, 0, 1)\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Layer: Current Dropout Rate: 20.0% | Loss: 0.253\n",
      "Example Layer: Current Dropout Rate: 18.8% | Loss: 0.253\n",
      "Example Layer: Current Dropout Rate: 17.5% | Loss: 0.206\n",
      "Example Layer: Current Dropout Rate: 16.5% | Loss: 0.177\n",
      "Example Layer: Current Dropout Rate: 15.8% | Loss: 0.232\n",
      "Example Layer: Current Dropout Rate: 14.6% | Loss: 0.127\n",
      "Example Layer: Current Dropout Rate: 14.4% | Loss: 0.172\n",
      "Example Layer: Current Dropout Rate: 13.7% | Loss: 0.183\n",
      "Example Layer: Current Dropout Rate: 12.9% | Loss: 0.176\n",
      "Example Layer: Current Dropout Rate: 12.2% | Loss: 0.094\n",
      "Example Layer: Current Dropout Rate: 12.3% | Loss: 0.149\n",
      "Example Layer: Current Dropout Rate: 11.9% | Loss: 0.115\n",
      "Example Layer: Current Dropout Rate: 11.7% | Loss: 0.100\n",
      "Example Layer: Final Dropout Rate: 11.7% | Loss: 0.100\n",
      "\n",
      "Input shape: torch.Size([32, 10])\n",
      "Output shape: torch.Size([32, 10])\n",
      "\n",
      "Initial dropout rate: 0.2\n",
      "Final dropout rate: 0.11726853707942174\n"
     ]
    }
   ],
   "source": [
    "# Create sample data\n",
    "torch.manual_seed(123)\n",
    "initial_p = 0.2\n",
    "information_loss_threshold  = 0.10\n",
    "batch_size = 32\n",
    "feature_dim = 10\n",
    "x = torch.randn(batch_size, feature_dim)\n",
    "\n",
    "# Configure the dropout layer\n",
    "optimizer_config = OptimizerConfig(\n",
    "    max_iterations=30,\n",
    "    learning_rate=0.1,\n",
    "    decay_rate=0.9,\n",
    "    stopping_error=0.001\n",
    ")\n",
    "\n",
    "# Create the adaptive dropout layer\n",
    "dropout = AdaptiveInformationDropout(\n",
    "    initial_p = initial_p,\n",
    "    calc_information_loss=calculate_information_loss,\n",
    "    information_loss_threshold = information_loss_threshold,\n",
    "    optimizer_config=optimizer_config,\n",
    "    name = 'Example Layer',\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Apply dropout\n",
    "output = dropout(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "print()\n",
    "print(\"Initial dropout rate:\", initial_p)\n",
    "print(\"Final dropout rate:\", dropout.p.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
